{"cells":[{"cell_type":"markdown","metadata":{},"source":["# This code is for providing the data augmentation by using the YOLOv8 Architecture.\n","\n","Input : \n","1. Directory Names of content images. [Healthy Leaf Directory of Different Plants]\n","2. Directory Names of style images. [Hand Picked Infected Leaf Images of Different Plants]\n","\n","Output :\n","1. Directory for all the style images where the augmented will be saved. [14 directories in case of segmented PlantVillage Dataset]\n","2. This output will be used by the Augmentation Validation Classifier to include only relevent imgaes in the Actual Dataset.\n","\n","Functioning of this code : \n","1. We initiate the style transfer using the hand-picked styles from each class on the healty image datast for each crop and save the images in respective folder."]},{"cell_type":"markdown","metadata":{},"source":["# Loading the Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T02:39:08.257231Z","iopub.status.busy":"2024-04-06T02:39:08.256887Z","iopub.status.idle":"2024-04-06T02:39:25.164967Z","shell.execute_reply":"2024-04-06T02:39:25.163882Z","shell.execute_reply.started":"2024-04-06T02:39:08.257201Z"},"trusted":true},"outputs":[],"source":["!pip install ultralytics"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T02:39:25.167336Z","iopub.status.busy":"2024-04-06T02:39:25.167042Z","iopub.status.idle":"2024-04-06T02:39:38.100667Z","shell.execute_reply":"2024-04-06T02:39:38.099794Z","shell.execute_reply.started":"2024-04-06T02:39:25.167310Z"},"trusted":true},"outputs":[],"source":["import os\n","import cv2\n","import torch\n","import numpy as np\n","from PIL import Image\n","from torch import optim\n","from ultralytics import YOLO\n","import matplotlib.pyplot as plt\n","from torchvision import transforms as T\n","from scipy.spatial.distance import euclidean\n","from skimage.feature import graycomatrix, graycoprops\n","\n","# device: str = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n","device = \"cuda\"\n","\n","model = YOLO('/kaggle/input/custom-trained-yolov8-plant-disease/custom-trained-yolov8-seg.pt')\n","yolo_model = model.model.model\n","for parameters in yolo_model:\n","    yolo_model.requires_grad_(False)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T02:39:38.102294Z","iopub.status.busy":"2024-04-06T02:39:38.101884Z","iopub.status.idle":"2024-04-06T02:39:38.469491Z","shell.execute_reply":"2024-04-06T02:39:38.468540Z","shell.execute_reply.started":"2024-04-06T02:39:38.102270Z"},"trusted":true},"outputs":[],"source":["i = 0\n","model_layers = {}\n","for name, layer in model._modules.items():\n","    for name_l, layer_l in layer._modules.items():\n","        for name_ll, layer_ll in layer_l._modules.items():\n","            model_layers[str(i)] = layer_ll\n","            i += 1\n","yolo_model.to(device)"]},{"cell_type":"markdown","metadata":{},"source":["# Augmentation code starts from here."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T02:39:38.472104Z","iopub.status.busy":"2024-04-06T02:39:38.471818Z","iopub.status.idle":"2024-04-06T02:39:38.479227Z","shell.execute_reply":"2024-04-06T02:39:38.478221Z","shell.execute_reply.started":"2024-04-06T02:39:38.472080Z"},"trusted":true},"outputs":[],"source":["content_images_dir_list = [\n","    '/kaggle/input/plantvillage/PlantVillage/train/Apple___healthy',\n","    '/kaggle/input/plantvillage/PlantVillage/train/Corn_(maize)___healthy',\n","    '/kaggle/input/plantvillage/PlantVillage/train/Grape___healthy',\n","    '/kaggle/input/plantvillage/PlantVillage/train/Pepper,_bell___healthy',\n","    '/kaggle/input/plantvillage/PlantVillage/train/Strawberry___healthy',\n","    '/kaggle/input/plantvillage/PlantVillage/train/Tomato___healthy'\n","]\n","\n","style_images_apple_dir_list = {\n","    '/kaggle/input/plantvillage/PlantVillage/train/Apple___Apple_scab': 100,\n","    '/kaggle/input/plantvillage/PlantVillage/train/Apple___Black_rot': 100,\n","    '/kaggle/input/plantvillage/PlantVillage/train/Apple___Cedar_apple_rust': 100,\n","}\n","\n","style_images_corn_dir_list = {\n","    '/kaggle/input/plantvillage/PlantVillage/train/Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot': 100,\n","    '/kaggle/input/plantvillage/PlantVillage/train/Corn_(maize)___Common_rust_': 100,\n","    '/kaggle/input/plantvillage/PlantVillage/train/Corn_(maize)___Northern_Leaf_Blight': 100, \n","}\n","\n","style_images_grape_dir_list = {\n","    '/kaggle/input/plantvillage/PlantVillage/train/Grape___Black_rot':100,\n","    '/kaggle/input/plantvillage/PlantVillage/train/Grape___Esca_(Black_Measles)': 100,\n","    '/kaggle/input/plantvillage/PlantVillage/train/Grape___Leaf_blight_(Isariopsis_Leaf_Spot)':100,\n","}\n","\n","style_images_pepper_dir_list = {\n","    '/kaggle/input/plantvillage/PlantVillage/train/Pepper,_bell___Bacterial_spot': 100,\n","}\n","\n","style_images_strawberry_dir_list = {\n","    '/kaggle/input/plantvillage/PlantVillage/train/Strawberry___Leaf_scorch': 100,\n","}\n","\n","style_images_tomato_dir_list = {\n","    '/kaggle/input/plantvillage/PlantVillage/train/Tomato___Bacterial_spot': 100,\n","    '/kaggle/input/plantvillage/PlantVillage/train/Tomato___Early_blight': 100, \n","    '/kaggle/input/plantvillage/PlantVillage/train/Tomato___Late_blight': 100, \n","    '/kaggle/input/plantvillage/PlantVillage/train/Tomato___Leaf_Mold': 100,\n","    '/kaggle/input/plantvillage/PlantVillage/train/Tomato___Septoria_leaf_spot': 100,\n","    '/kaggle/input/plantvillage/PlantVillage/train/Tomato___Spider_mites Two-spotted_spider_mite': 100,\n","    '/kaggle/input/plantvillage/PlantVillage/train/Tomato___Target_Spot': 100,\n","    '/kaggle/input/plantvillage/PlantVillage/train/Tomato___Tomato_mosaic_virus': 100,\n","    '/kaggle/input/plantvillage/PlantVillage/train/Tomato___Tomato_Yellow_Leaf_Curl_Virus': 100,\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T02:39:38.480968Z","iopub.status.busy":"2024-04-06T02:39:38.480565Z","iopub.status.idle":"2024-04-06T02:39:38.502269Z","shell.execute_reply":"2024-04-06T02:39:38.501538Z","shell.execute_reply.started":"2024-04-06T02:39:38.480936Z"},"trusted":true},"outputs":[],"source":["def preprocess(img_path, max_size = 640):\n","  image = Image.open(img_path).convert('RGB')\n","  img_transforms = T.Compose([\n","      T.ToTensor(),  # (224, 224, 3) -> (3, 224, 224)\n","      T.Normalize(mean = [0.485, 0.456, 0.406],\n","                  std = [0.229, 0.224, 0.225])\n","  ])\n","  image = img_transforms(image)\n","  image = image.unsqueeze(0) # (3, 224, 224) -> (1, 3, 224, 224)\n","  return image\n","\n","def deprocess(tensor):\n","  image = tensor.to('cpu').clone()\n","  image = image.numpy()\n","  image = image.squeeze(0)\n","  image = image.transpose(1, 2, 0)\n","  # denormalizing the image\n","  image = image * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n","  image = image.clip(0, 1)\n","  return image\n","\n","def get_features(image, model):\n","  layers = {\n","\n","            '1' : 'conv1_1',\n","            '2' : 'conv2_1',\n","            '4' : 'conv3_1',\n","            '7' : 'conv4_1',\n","            '8' : 'conv4_2',\n","            '10' : 'conv5_1'\n","  }\n","  x = image\n","  Features = {}\n","  i = 0\n","  for name in model_layers.keys():\n","    x = model_layers[name](x)\n","    if name in layers:\n","      Features[layers[name]] = x\n","    i += 1\n","    if (i > 10):\n","      break\n","  return Features\n","\n","def gram_matrix(tensor):\n","  b, c, h, w = tensor.size()\n","  tensor = tensor.view(c, h*w)\n","  gram = torch.mm(tensor, tensor.t())\n","  return gram\n","\n","def content_loss(target_conv4_2, content_conv4_2):\n","  loss = torch.mean((target_conv4_2 - content_conv4_2)**2)\n","  return loss\n","\n","style_weights_1 = {\n","\n","    'conv1_1' : 0.2,\n","    'conv2_1' : 0.2,\n","    'conv3_1' : 0.5,\n","    'conv4_1' : 1.0,\n","    'conv5_1' : 0.2\n","}\n","\n","style_weights_arr = [style_weights_1]\n","\n","def style_loss(style_weights, target_features, style_grams):\n","  loss = 0\n","  for layer in style_weights:\n","    target_f = target_features[layer]\n","    target_gram = gram_matrix(target_f)\n","    style_gram = style_grams[layer]\n","    b, c, h, w = target_f.shape\n","    layer_loss = style_weights[layer] * torch.mean((target_gram - style_gram)**2)\n","    loss += layer_loss/(c*h*w)\n","  return loss\n","\n","def total_loss(c_loss, s_loss, alpha, beta):\n","  loss = alpha * c_loss + beta * s_loss\n","  return loss\n","\n","def glcm_features(image):\n","    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","    glcm = graycomatrix(gray_image, [1], [0], 256, symmetric=True, normed=True)\n","    contrast = graycoprops(glcm, 'contrast').flatten()\n","    correlation = graycoprops(glcm, 'correlation').flatten()\n","    energy = graycoprops(glcm, 'energy').flatten()\n","    homogeneity = graycoprops(glcm, 'homogeneity').flatten()\n","    return contrast, correlation, energy, homogeneity\n","\n","def calculate_similarity(feature1, feature2):\n","    distance = 0\n","    for f1, f2 in zip(feature1, feature2):\n","        distance += (f1 - f2)**2\n","    return distance**0.5\n","\n","def imread(path):\n","    img = cv2.imread(path).astype(np.float)\n","    if len(img.shape) == 2:\n","        # grayscale\n","        img = np.dstack((img,img,img))\n","    elif img.shape[2] == 4:\n","        # PNG with alpha channel\n","        img = img[:,:,:3]\n","    return img\n","\n","def imsave(path, img):\n","    img = np.clip(img, 0, 255).astype(np.uint8)\n","    Image.fromarray(img).save(path, quality=95)"]},{"cell_type":"markdown","metadata":{},"source":["# Augment Dataset"]},{"cell_type":"markdown","metadata":{},"source":["**Upload custom trained yolov8 before this**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T02:39:38.504170Z","iopub.status.busy":"2024-04-06T02:39:38.503181Z","iopub.status.idle":"2024-04-06T02:39:38.837115Z","shell.execute_reply":"2024-04-06T02:39:38.836070Z","shell.execute_reply.started":"2024-04-06T02:39:38.504136Z"},"trusted":true},"outputs":[],"source":["model = YOLO('/kaggle/input/custom-trained-yolov8-plant-disease/custom-trained-yolov8-seg.pt')\n","model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T02:39:38.838712Z","iopub.status.busy":"2024-04-06T02:39:38.838407Z","iopub.status.idle":"2024-04-06T02:39:38.999678Z","shell.execute_reply":"2024-04-06T02:39:38.998587Z","shell.execute_reply.started":"2024-04-06T02:39:38.838688Z"},"trusted":true},"outputs":[],"source":["def nst_data_augment(content_img_path, style_img_path, final_image_name, final_image_path, style_weights):\n","    content_p = preprocess(content_img_path)\n","    style_p = preprocess(style_img_path)\n","    content_p = content_p.to(device)\n","    style_p = style_p.to(device)\n","\n","    #Getting the features from the image and calculation of Gram Matrix\n","\n","    content_f = get_features(content_p, yolo_model)\n","    style_f = get_features(style_p, yolo_model)\n","    style_grams = { layer : gram_matrix(style_f[layer]) for layer in style_f }\n","    target = content_p.clone().requires_grad_(True).to(device)\n","    target_f = get_features(target, yolo_model)\n","\n","    #Calculation of the losses and their optimization.\n","\n","    optimizer = optim.Adam([target], lr = 0.08)\n","    alpha = 1\n","    beta = 1e6\n","    epochs = 801\n","    show_every = 200\n","    results = []\n","    for i in range(epochs):\n","        target_f = get_features(target, yolo_model)\n","\n","        c_loss = content_loss(target_f['conv4_2'], content_f['conv4_2'])\n","        s_loss = style_loss(style_weights_arr[style_weights], target_f, style_grams)\n","\n","        t_loss = total_loss(c_loss, s_loss, alpha, beta)\n","\n","        optimizer.zero_grad()\n","        t_loss.backward()\n","        optimizer.step()\n","\n","        if i % show_every == 0:\n","            print(\"Total loss at epoch {}: {}\".format(i, t_loss))\n","            results.append(deprocess(target.detach()))\n","\n","    target_copy = deprocess(target.detach())\n","    content_copy = deprocess(content_p)\n","    plt.imsave(\"target.png\", target_copy)\n","    plt.imsave(\"content.png\", content_copy)\n","    imgcon = cv2.imread('content.png')\n","    imgcon = cv2.cvtColor(imgcon, cv2.COLOR_BGR2RGB)\n","    H, W, _ = imgcon.shape\n","    results = model(imgcon)\n","    i = 0\n","    mask_present = 0\n","    for result in results:\n","        for j, mask in enumerate(result.masks.data):\n","            mask = mask.cpu().numpy() * 255\n","            mask  =cv2.resize(mask, (W, H))\n","            cv2.imwrite('./mask.png', mask)\n","            if i == 0:\n","                mask_present = 1\n","                break\n","            i += 1\n","    if (mask_present):\n","        imgtar = cv2.imread(\"target.png\")\n","        imgtar = cv2.cvtColor(imgtar, cv2.COLOR_BGR2RGB)\n","        imgtar = imgtar.astype(np.uint8)\n","        imgtar = cv2.resize(imgtar, (W, H))\n","        mask = cv2.imread('./mask.png', cv2.IMREAD_GRAYSCALE)\n","        _, binary_mask = cv2.threshold(mask, 1, 255, cv2.THRESH_BINARY)\n","        masked_overlay = cv2.bitwise_or(imgtar, imgtar, mask=binary_mask)\n","        masked_overlay = masked_overlay.astype(np.uint8)\n","        inverted_mask = cv2.bitwise_not(binary_mask.astype(np.uint8))\n","        roi = cv2.bitwise_and(imgcon, imgcon, mask=inverted_mask)\n","        result_image = cv2.add(roi, masked_overlay)\n","        plt.imsave(os.path.join(final_image_path, final_image_name), result_image)\n","\n","\n","def nst_data_augment_without_segmentation(content_img_path, style_img_path, final_image_name, final_image_path, style_weights):\n","    content_p = preprocess(content_img_path)\n","    style_p = preprocess(style_img_path)\n","    content_p = content_p.to(device)\n","    style_p = style_p.to(device)\n","\n","    #Getting the features from the image and calculation of Gram Matrix\n","\n","    content_f = get_features(content_p, yolo_model)\n","    style_f = get_features(style_p, yolo_model)\n","    style_grams = { layer : gram_matrix(style_f[layer]) for layer in style_f }\n","    target = content_p.clone().requires_grad_(True).to(device)\n","    target_f = get_features(target, yolo_model)\n","\n","    #Calculation of the losses and their optimization.\n","\n","    optimizer = optim.Adam([target], lr = 0.08)\n","    alpha = 1\n","    beta = 1e6\n","    epochs = 801\n","    show_every = 200\n","    results = []\n","    for i in range(epochs):\n","        target_f = get_features(target, yolo_model)\n","\n","        c_loss = content_loss(target_f['conv4_2'], content_f['conv4_2'])\n","        s_loss = style_loss(style_weights_arr[style_weights], target_f, style_grams)\n","\n","        t_loss = total_loss(c_loss, s_loss, alpha, beta)\n","\n","        optimizer.zero_grad()\n","        t_loss.backward()\n","        optimizer.step()\n","\n","        if i % show_every == 0:\n","            print(\"Total loss at epoch {}: {}\".format(i, t_loss))\n","            results.append(deprocess(target.detach()))\n","\n","    target_copy = deprocess(target.detach())\n","    plt.imsave(os.path.join(final_image_path, final_image_name), target_copy)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T02:39:39.001213Z","iopub.status.busy":"2024-04-06T02:39:39.000901Z","iopub.status.idle":"2024-04-06T02:39:39.017453Z","shell.execute_reply":"2024-04-06T02:39:39.016686Z","shell.execute_reply.started":"2024-04-06T02:39:39.001189Z"},"trusted":true},"outputs":[],"source":["weights_data = {\n","    'Apple___Cedar_apple_rust': 1,\n","    'Apple___Apple_scab': 3,\n","    'Apple___Black_rot': 4,\n","    'Corn_(maize)___Common_rust_': 0,\n","    'Corn_(maize)___Northern_Leaf_Blight': 0,\n","    'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot': 0,\n","    'Grape___Black_rot': 0,\n","    'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)': 0,\n","    'Grape___Esca_(Black_Measles)': 0,\n","    'Pepper,_bell___Bacterial_spot': 0,\n","    'Strawberry___Leaf_scorch': 1,\n","    'Tomato___Target_Spot': 0,\n","    'Tomato___Late_blight': 0,\n","    'Tomato___Tomato_mosaic_virus': 0,\n","    'Tomato___Leaf_Mold': 0,\n","    'Tomato___Bacterial_spot': 0,\n","    'Tomato___Early_blight': 0,\n","    'Tomato___Tomato_Yellow_Leaf_Curl_Virus': 0,\n","    'Tomato___Spider_mites Two-spotted_spider_mite': 0,\n","    'Tomato___Septoria_leaf_spot': 0\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T02:41:59.453409Z","iopub.status.busy":"2024-04-06T02:41:59.452798Z","iopub.status.idle":"2024-04-06T02:41:59.466445Z","shell.execute_reply":"2024-04-06T02:41:59.465660Z","shell.execute_reply.started":"2024-04-06T02:41:59.453380Z"},"trusted":true},"outputs":[],"source":["def augment_plant_dataset(content_data_dir, style_data_dir_list, final_output_directory, with_segmentation, skip):\n","    num_skip = skip\n","    for healthy_image_file in os.listdir(content_data_dir):\n","        healthy_image_path = os.path.join(content_data_dir, healthy_image_file)\n","        if os.path.isfile(healthy_image_path):\n","            healthy_image = cv2.imread(healthy_image_path)\n","            if healthy_image is not None: \n","                if num_skip > 0:\n","                    num_skip -= 1\n","                    continue\n","                healthy_features = glcm_features(healthy_image)\n","                for diseased_folder in style_data_dir_list:\n","                    best_similarity = float('inf')\n","                    best_diseased_leaf_image = None\n","                    for diseased_image_file in os.listdir(os.path.join(diseased_folder)):\n","                        diseased_image_path = os.path.join(diseased_folder, diseased_image_file)\n","                        if os.path.isfile(diseased_image_path):\n","                            diseased_image = cv2.imread(diseased_image_path)\n","                            if diseased_image is not None:  # Check if image is loaded successfully\n","                                diseased_features = glcm_features(diseased_image)\n","                                similarity = calculate_similarity(healthy_features, diseased_features)\n","                                if similarity < best_similarity:\n","                                    best_similarity = similarity\n","                                    best_diseased_leaf_image = diseased_image_path\n","                    if best_diseased_leaf_image is not None:\n","                        # print(f\"For healthy leaf image {healthy_image_file}, most similar diseased leaf image in folder {diseased_folder} is {best_diseased_leaf_image} with similarity score {best_similarity}\")\n","                        index = diseased_folder.rfind(\"/\")\n","                        diseased_folder_name = diseased_folder[index+1:]\n","                        augmented_path = os.path.join(final_output_directory, diseased_folder_name)\n","                        os.makedirs(augmented_path, exist_ok=True)\n","                        index = healthy_image_file.rfind(\".\")\n","                        augmented_image_name = healthy_image_file[:index] + \"_augmented.\" + healthy_image_file[index+1:]\n","                        print(\"Transfering the style for : \" + str(healthy_image_path))\n","                        if with_segmentation:\n","                            nst_data_augment(healthy_image_path, best_diseased_leaf_image, augmented_image_name, augmented_path, weights_data[diseased_folder_name])\n","                        else:\n","                            nst_data_augment_without_segmentation(healthy_image_path, best_diseased_leaf_image, augmented_image_name, augmented_path, weights_data[diseased_folder_name])\n","                    else:\n","                        print(f\"No suitable diseased leaf image found for healthy leaf image {healthy_image_file} in folder {diseased_folder}\")\n","            else:\n","                print(f\"Error loading healthy leaf image: {healthy_image_path}\")\n","        else:\n","            print(f\"Invalid file: {healthy_image_path}\")\n"]},{"cell_type":"markdown","metadata":{},"source":["**Make changes here as per augmentation to be made**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T02:42:41.777319Z","iopub.status.busy":"2024-04-06T02:42:41.776954Z"},"trusted":true},"outputs":[],"source":["augment_plant_dataset(content_images_dir_list[5], list(style_images_tomato_dir_list.keys()), '/kaggle/working/plantvillage-augmented-tomato-3', True, 548)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-06T11:15:36.402136Z","iopub.status.busy":"2024-04-06T11:15:36.401221Z","iopub.status.idle":"2024-04-06T11:15:37.913073Z","shell.execute_reply":"2024-04-06T11:15:37.911944Z","shell.execute_reply.started":"2024-04-06T11:15:36.402103Z"},"trusted":true},"outputs":[],"source":["!zip -r file-tomato-3.zip /kaggle/working/plantvillage-augmented-tomato-3/Tomato___Tomato_Yellow_Leaf_Curl_Virus"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":1541807,"sourceId":2542588,"sourceType":"datasetVersion"},{"datasetId":4508417,"sourceId":7730861,"sourceType":"datasetVersion"}],"dockerImageVersionId":30665,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
