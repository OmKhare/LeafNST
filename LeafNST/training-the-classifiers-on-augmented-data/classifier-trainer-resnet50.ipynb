{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Original Dataset is in : ../data/PlantVillage/\n",
        "#This dataset is the dataset from here : https://www.kaggle.com/datasets/soumiknafiul/plantvillage-dataset-labeled\n",
        "\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "# Define paths\n",
        "input_folder = \"../augmentation-validation/classified-augmented-original\"\n",
        "train_folder = \"../augmentation-validation/classified-augmented-original-div/train\"\n",
        "val_folder = \"../augmentation-validation/classified-augmented-original-div/val\"\n",
        "\n",
        "# Create train and validation folders if they don't exist\n",
        "os.makedirs(train_folder, exist_ok=True)\n",
        "os.makedirs(val_folder, exist_ok=True)\n",
        "\n",
        "# Function to divide images into train and validation sets\n",
        "def split_dataset(input_folder, train_folder, val_folder, split_ratio=0.8):\n",
        "    for root, dirs, files in os.walk(input_folder):\n",
        "        for dir_name in dirs:\n",
        "            # Create corresponding folders in train and validation sets\n",
        "            train_dir = os.path.join(train_folder, root[len(input_folder)+1:], dir_name)\n",
        "            val_dir = os.path.join(val_folder, root[len(input_folder)+1:], dir_name)\n",
        "            os.makedirs(train_dir, exist_ok=True)\n",
        "            os.makedirs(val_dir, exist_ok=True)\n",
        "            \n",
        "            # Get list of all image files in the subfolder\n",
        "            image_files = [f for f in os.listdir(os.path.join(root, dir_name)) if f.endswith(('.jpg', '.jpeg', '.png', '.JPG'))]\n",
        "            \n",
        "            # Shuffle the list of image files\n",
        "            random.shuffle(image_files)\n",
        "            \n",
        "            # Calculate number of images for train and validation sets\n",
        "            num_images = len(image_files)\n",
        "            num_train = int(split_ratio * num_images)\n",
        "            num_val = num_images - num_train\n",
        "            \n",
        "            # Split the image files into train and validation sets\n",
        "            train_images = image_files[:num_train]\n",
        "            val_images = image_files[num_train:]\n",
        "            \n",
        "            # Copy train images to train folder\n",
        "            for image in train_images:\n",
        "                src = os.path.join(root, dir_name, image)\n",
        "                dst = os.path.join(train_dir, image)\n",
        "                shutil.copyfile(src, dst)\n",
        "            \n",
        "            # Copy validation images to validation folder\n",
        "            for image in val_images:\n",
        "                src = os.path.join(root, dir_name, image)\n",
        "                dst = os.path.join(val_dir, image)\n",
        "                shutil.copyfile(src, dst)\n",
        "\n",
        "# Split the dataset into train and validation sets\n",
        "split_dataset(input_folder, train_folder, val_folder)\n",
        "\n",
        "print(\"Dataset split into train and validation sets successfully.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "def copy_folder_contents(source_dir, dest_dir):\n",
        "    for root, dirs, files in os.walk(source_dir):\n",
        "        # Get the relative path from the source directory\n",
        "        relative_path = os.path.relpath(root, source_dir)\n",
        "        \n",
        "        # Construct the corresponding destination directory\n",
        "        dest_path = os.path.join(dest_dir, relative_path)\n",
        "        \n",
        "        # Ensure the destination directory exists\n",
        "        os.makedirs(dest_path, exist_ok=True)\n",
        "        \n",
        "        # Copy files\n",
        "        for file in files:\n",
        "            src_file = os.path.join(root, file)\n",
        "            dest_file = os.path.join(dest_path, file)\n",
        "            shutil.copy(src_file, dest_file)\n",
        "\n",
        "source_folder = \"../augmentation-validation/classified-augmented-original-div/val\"\n",
        "destination_folder = \"../augmentation-validation/nst-augmented/PlantVillage/val\"\n",
        "\n",
        "copy_folder_contents(source_folder, destination_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vbFUNg3tKo8d"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import copy\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Subset\n",
        "from torch.autograd import Variable\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision import datasets, transforms, models\n",
        "from collections import OrderedDict\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import lr_scheduler\n",
        "from sklearn import metrics\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWFKFA4mwyxj"
      },
      "source": [
        "# Load PlantVillage Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ApU2YvYFd_d",
        "outputId": "27444dea-9e34-40d3-8a1f-9cf019b4189b"
      },
      "outputs": [],
      "source": [
        "#Organizing the dataset\n",
        "batch_size = 32\n",
        "\n",
        "# check if CUDA is available\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "train_on_gpu_mps = torch.backends.mps.is_available()\n",
        "\n",
        "if train_on_gpu:\n",
        "    print('CUDA is available.  Training on GPU ...')\n",
        "    device = torch.device(\"cuda:0\")\n",
        "if train_on_gpu_mps:\n",
        "    print('MPS is available!  Training on GPU ...')\n",
        "    device = torch.device(\"mps\")\n",
        "else:\n",
        "    print('Training on CPU ...')\n",
        "    device = torch.device(\"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJ-O_ly5YVz8"
      },
      "outputs": [],
      "source": [
        "def balanced_sampler_weights(images, nclasses):\n",
        "  count = [0] * nclasses\n",
        "  for img in images:\n",
        "    count[img[1]] += 1\n",
        "  total_num_imgs = float(sum(count))\n",
        "\n",
        "  weight_per_class = [total_num_imgs/float(count[i]) for i in range(nclasses)]\n",
        "  weight_per_img = [weight_per_class[img[1]] for _, img in enumerate(images)]\n",
        "  return weight_per_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5KnbE3_KmhW",
        "outputId": "7ffba5c6-7bb8-4305-bed2-0f0de90fdc31"
      },
      "outputs": [],
      "source": [
        "# Define your transforms for the training and validation sets\n",
        "# Data augmentation and normalization for training\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        # transforms.RandomAffine(0,shear=30),\n",
        "        transforms.RandomRotation(30),\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "data_dir = '../augmentation-validation/nst-augmented/PlantVillage'\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
        "\n",
        "balance_classes = False\n",
        "\n",
        "if balance_classes:\n",
        "  train_weights = balanced_sampler_weights(image_datasets['train'].imgs, len(image_datasets['train'].classes))\n",
        "  train_weights = torch.DoubleTensor(train_weights)\n",
        "  train_sampler = torch.utils.data.sampler.WeightedRandomSampler(train_weights, len(train_weights))\n",
        "  samplers = {'train': train_sampler, 'val': None}\n",
        "\n",
        "  # Using the image datasets and the trainforms, define the dataloaders\n",
        "  dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, sampler=samplers[x], num_workers=4) for x in ['train', 'val']}\n",
        "else:\n",
        "  print(\"No balancing\")\n",
        "  # Using the image datasets and the trainforms, define the dataloaders\n",
        "  dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val']}\n",
        "\n",
        "# data\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "\n",
        "x,y = next(iter(dataloaders['train']))\n",
        "print(x.shape, y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WlJKJ3g-VNCJ"
      },
      "outputs": [],
      "source": [
        "tmp = dataloaders['train']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lM8PMyeFpCXi"
      },
      "outputs": [],
      "source": [
        "buckets_split = {}\n",
        "for split in ['train', 'val']:\n",
        "  classes = image_datasets[split].classes\n",
        "  buckets_split[split] = {x: 0 for x in classes}\n",
        "\n",
        "print(classes)\n",
        "\n",
        "for split in ['train', 'val']:\n",
        "  ds = dataloaders[split]\n",
        "  for data, batch_target in ds:\n",
        "    for target in batch_target:\n",
        "      class_idx = target.item()\n",
        "      buckets_split[split][classes[class_idx]] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "LwrTFv6QtepQ",
        "outputId": "11677d86-e038-425b-de28-a25c5354a5de"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20,5))\n",
        "ind = range(len(buckets_split['train'].keys()))\n",
        "p1 = plt.bar(ind,list(buckets_split['train'].values()))\n",
        "p2 = plt.bar(ind,list(buckets_split['val'].values()), bottom=list(buckets_split['train'].values()))\n",
        "plt.title(\"PlantVillage dataset class distribution\")\n",
        "plt.ylabel('Number of samples')\n",
        "plt.xlabel('Plant disease class')\n",
        "plt.xticks(ticks=ind, labels=classes, rotation = 'vertical')\n",
        "plt.legend((p1[0], p2[0]), ('Train', 'Validation'))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZTxeBRhw3v4"
      },
      "source": [
        "# Build and train classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OaTKXHH-o5t-"
      },
      "outputs": [],
      "source": [
        "model = models.resnet50(pretrained=True)\n",
        "\n",
        "# for param in model.parameters():\n",
        "#   param.requires_grad = False\n",
        "# model = models.resnet50(pretrained=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kv6rG0SAymOL"
      },
      "outputs": [],
      "source": [
        "classifier = nn.Sequential(OrderedDict([('fc1', nn.Linear(2048, 512)),\n",
        "                                        ('relu', nn.ReLU()),\n",
        "                                        ('fc2', nn.Linear(512,38)),\n",
        "                                        ('output', nn.LogSoftmax(dim=1))]))\n",
        "\n",
        "model.fc = classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KTV9x5EiynlT"
      },
      "outputs": [],
      "source": [
        "#Function to train the model\n",
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=50):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(1, num_epochs+1):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs))\n",
        "        print('-' * 10)\n",
        "\n",
        "        model.train()  # Set model to training mode\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "\n",
        "        # Train and update weights\n",
        "        for inputs, labels in dataloaders['train']:\n",
        "          inputs, labels = inputs.to(device), labels.to(device)\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          # Forward\n",
        "          outputs = model(inputs)\n",
        "          loss = criterion(outputs, labels)\n",
        "          _, preds = torch.max(outputs,1)\n",
        "\n",
        "          # Backward + optimize\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          # statistics\n",
        "          running_loss += loss.item() * inputs.size(0)\n",
        "          running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        scheduler.step()\n",
        "        running_loss = np.float32(running_loss)\n",
        "        running_corrects = np.float32(running_corrects.cpu())\n",
        "        epoch_loss = running_loss / dataset_sizes['train']\n",
        "        epoch_acc = running_corrects / dataset_sizes['train']\n",
        "\n",
        "        print(f\"Train Loss: {epoch_loss} Acc: {epoch_acc}\")\n",
        "\n",
        "        # Evaluate on validation set\n",
        "        model.eval()\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "\n",
        "        # Iterate over data.\n",
        "        for inputs, labels in dataloaders['val']:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward\n",
        "            with torch.no_grad():\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            # statistics\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        running_loss = np.float32(running_loss)\n",
        "        running_corrects = np.float32(running_corrects.cpu())\n",
        "        epoch_loss = running_loss / dataset_sizes['val']\n",
        "        epoch_acc = running_corrects / dataset_sizes['val']\n",
        "\n",
        "        print(f\"Validation Loss: {epoch_loss} Acc: {epoch_acc}\")\n",
        "\n",
        "        # deep copy the model\n",
        "        if epoch_acc > best_acc:\n",
        "            best_acc = epoch_acc\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "        \n",
        "        if epoch % 5 == 0:\n",
        "            # Save model every 5 epochs\n",
        "            model.epochs = epoch\n",
        "            checkpoint = {'input_size': [3, 224, 224],\n",
        "                  'batch_size': dataloaders['train'].batch_size,\n",
        "                  'output_size': 17,\n",
        "                  'state_dict': model.state_dict(),\n",
        "                  'data_transforms': data_transforms,\n",
        "                  'optimizer_dict':optimizer.state_dict(),\n",
        "                  'epoch': model.epochs}\n",
        "            torch.save(checkpoint, f\"classifier_{epoch}_epochs_checkpoint.pth\")\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best valid accuracy: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oL8pSxywqRgw"
      },
      "source": [
        "## Train the classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WILJnBjFqXHW",
        "outputId": "8ad2e959-3be0-415b-be68-5f0901543903"
      },
      "outputs": [],
      "source": [
        "# Train a model with a pre-trained network\n",
        "num_epochs = 5\n",
        "if train_on_gpu:\n",
        "    print (\"Using GPU: \"+ str(train_on_gpu))\n",
        "    model = model.cuda()\n",
        "if train_on_gpu_mps:\n",
        "    print (\"Using GPU: \"+ str(train_on_gpu_mps))\n",
        "    model = model.to(device)\n",
        "\n",
        "# NLLLoss because our output is LogSoftmax\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "# Adam optimizer with a learning rate\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
        "# Decay LR by a factor of 0.1 every 5 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
        "\n",
        "\n",
        "model_ft = train_model(model, criterion, optimizer, exp_lr_scheduler, num_epochs=num_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7QNvVryOqXHX"
      },
      "outputs": [],
      "source": [
        "# Do validation on the test set\n",
        "def test(model, dataloaders, device):\n",
        "  model.eval()\n",
        "  accuracy = 0\n",
        "  \n",
        "  model.to(device)\n",
        "  \n",
        "  label_accuracy = {x: 0 for x in image_datasets['val'].classes}\n",
        "  predicted_labels = []\n",
        "  true_labels = []\n",
        "\n",
        "  for images, labels in dataloaders['val']:\n",
        "    images = Variable(images)\n",
        "    labels = Variable(labels)\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "      \n",
        "    output = model.forward(images)\n",
        "    ps = torch.exp(output)\n",
        "    equality = (labels.data == ps.max(1)[1])\n",
        "    acc = equality.type_as(torch.FloatTensor())\n",
        "    accuracy += acc.mean()\n",
        "    for i,x in enumerate(labels.data):\n",
        "      label_accuracy[image_datasets['val'].classes[x]] += acc[i]\n",
        "      predicted_labels.append(ps.max(1)[1][i])\n",
        "      true_labels.append(x)\n",
        "\n",
        "  print(\"Testing Accuracy: {:.3f}\".format(accuracy/len(dataloaders['val'])))\n",
        "\n",
        "  return true_labels, predicted_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s3-s2Q0RqXHX"
      },
      "outputs": [],
      "source": [
        "model.epochs = num_epochs\n",
        "checkpoint = {'input_size': [3, 224, 224],\n",
        "                 'batch_size': dataloaders['train'].batch_size,\n",
        "                  'output_size': 17,\n",
        "                  'state_dict': model.state_dict(),\n",
        "                  'data_transforms': data_transforms,\n",
        "                  'optimizer_dict':optimizer.state_dict(),\n",
        "                  'epoch': model.epochs}\n",
        "torch.save(checkpoint, './plantvillage_resnet50.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9a1MNFGCqXHX",
        "outputId": "a54d9065-2252-4e57-d182-caf21e383012"
      },
      "outputs": [],
      "source": [
        "true_labels, predicted_labels = test(model, dataloaders, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxwQ0LMvqXHX"
      },
      "outputs": [],
      "source": [
        "predicted_labels_list = [x.cpu().item() for x in predicted_labels]\n",
        "true_labels_list = [x.cpu().item() for x in true_labels]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyMuFHytqXHX",
        "outputId": "4086beb5-d74c-4c39-e9ea-4fc8cbf5f6e5"
      },
      "outputs": [],
      "source": [
        "# Print the confusion matrix\n",
        "print(metrics.confusion_matrix(true_labels_list, predicted_labels_list))\n",
        "\n",
        "# Print the precision and recall, among other metrics\n",
        "print(metrics.classification_report(true_labels_list, predicted_labels_list, target_names=image_datasets['val'].classes, digits=3))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Plantdisease_all_augmentation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
