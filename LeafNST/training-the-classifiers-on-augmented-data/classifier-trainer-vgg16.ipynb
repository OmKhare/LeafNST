{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2542588,"sourceType":"datasetVersion","datasetId":1541807},{"sourceId":8090482,"sourceType":"datasetVersion","datasetId":4776455},{"sourceId":8094080,"sourceType":"datasetVersion","datasetId":4778827}],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torchvision import datasets, models, transforms\nimport os\nimport time\nimport copy\n\n# Define data directories\ndata_dir = \"/kaggle/input/plantvillage-traditional-augmentation/PlantVillage\"\ntrain_dir = data_dir + \"/kaggle/input/plantvillage-traditional-augmentation/PlantVillage/train\"\nval_dir = data_dir + \"/kaggle/input/plantvillage-traditional-augmentation/PlantVillage/val\"\n\n# Define transformation for the data\ndata_transforms = {\n    'train': transforms.Compose([\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    'val': transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n}\n\n# Load the datasets with ImageFolder\nimage_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x])\n                  for x in ['train', 'val']}\n\n# Define the dataloaders\ndataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4, shuffle=True, num_workers=4)\n               for x in ['train', 'val']}\n\n# Number of classes in the dataset\nnum_classes = 38\n\n# Load the pre-trained VGG16 model\nmodel = models.vgg16(pretrained=True)\n# Change the last fully connected layer to match the number of classes\n\n# Freeze all layers except the final fully connected layer\nfor param in model.parameters():\n    param.requires_grad = False\n\n# Modify the final fully connected layer to match the number of classes\nmodel.classifier[6] = nn.Linear(4096, num_classes)\n\n# Define the loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n\n# Decay LR by a factor of 0.1 every 7 epochs\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n\n# Function to train the model\ndef train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n    since = time.time()\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                # Zero the parameter gradients\n                optimizer.zero_grad()\n\n                # Forward\n                # Track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n\n                    # Backward + optimize only if in training phase\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                # Statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n            if phase == 'train':\n                scheduler.step()\n\n            epoch_loss = running_loss / len(image_datasets[phase])\n            epoch_acc = running_corrects.double().to(torch.float32) / len(image_datasets[phase])\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n                phase, epoch_loss, epoch_acc))\n\n            # Deep copy the model\n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed // 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n    \n    # Load best model weights\n    model.load_state_dict(best_model_wts)\n    return model\n\n# Train the model\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\n\nmodel = train_model(model, criterion, optimizer, exp_lr_scheduler, num_epochs=25)\n\n# Save the trained model\ntorch.save(model.state_dict(), 'custom_vgg16.pth')\n","metadata":{"execution":{"iopub.status.busy":"2024-04-11T19:05:10.811629Z","iopub.execute_input":"2024-04-11T19:05:10.811952Z","iopub.status.idle":"2024-04-11T20:44:23.465691Z","shell.execute_reply.started":"2024-04-11T19:05:10.811928Z","shell.execute_reply":"2024-04-11T20:44:23.464481Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n100%|██████████| 528M/528M [00:03<00:00, 179MB/s] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 0/24\n----------\ntrain Loss: 1.2758 Acc: 0.6535\nval Loss: 0.6899 Acc: 0.8161\n\nEpoch 1/24\n----------\ntrain Loss: 1.1753 Acc: 0.7001\nval Loss: 0.6038 Acc: 0.8389\n\nEpoch 2/24\n----------\ntrain Loss: 1.1645 Acc: 0.7123\nval Loss: 0.5339 Acc: 0.8509\n\nEpoch 3/24\n----------\ntrain Loss: 1.1538 Acc: 0.7170\nval Loss: 0.5030 Acc: 0.8625\n\nEpoch 4/24\n----------\ntrain Loss: 1.1670 Acc: 0.7211\nval Loss: 0.6477 Acc: 0.8461\n\nEpoch 5/24\n----------\ntrain Loss: 1.1379 Acc: 0.7269\nval Loss: 0.5430 Acc: 0.8563\n\nEpoch 6/24\n----------\ntrain Loss: 1.1433 Acc: 0.7285\nval Loss: 0.5089 Acc: 0.8650\n\nEpoch 7/24\n----------\ntrain Loss: 0.9799 Acc: 0.7503\nval Loss: 0.3729 Acc: 0.8920\n\nEpoch 8/24\n----------\ntrain Loss: 0.9044 Acc: 0.7614\nval Loss: 0.3451 Acc: 0.8978\n\nEpoch 9/24\n----------\ntrain Loss: 0.8527 Acc: 0.7704\nval Loss: 0.3489 Acc: 0.8976\n\nEpoch 10/24\n----------\ntrain Loss: 0.8199 Acc: 0.7726\nval Loss: 0.3478 Acc: 0.8941\n\nEpoch 11/24\n----------\ntrain Loss: 0.8151 Acc: 0.7757\nval Loss: 0.3209 Acc: 0.9027\n\nEpoch 12/24\n----------\ntrain Loss: 0.7962 Acc: 0.7756\nval Loss: 0.3093 Acc: 0.9027\n\nEpoch 13/24\n----------\ntrain Loss: 0.7835 Acc: 0.7791\nval Loss: 0.3100 Acc: 0.9042\n\nEpoch 14/24\n----------\ntrain Loss: 0.7606 Acc: 0.7826\nval Loss: 0.3019 Acc: 0.9054\n\nEpoch 15/24\n----------\ntrain Loss: 0.7558 Acc: 0.7834\nval Loss: 0.3049 Acc: 0.9054\n\nEpoch 16/24\n----------\ntrain Loss: 0.7577 Acc: 0.7830\nval Loss: 0.3069 Acc: 0.9046\n\nEpoch 17/24\n----------\ntrain Loss: 0.7518 Acc: 0.7838\nval Loss: 0.3023 Acc: 0.9066\n\nEpoch 18/24\n----------\ntrain Loss: 0.7455 Acc: 0.7839\nval Loss: 0.3071 Acc: 0.9040\n\nEpoch 19/24\n----------\ntrain Loss: 0.7598 Acc: 0.7804\nval Loss: 0.3026 Acc: 0.9048\n\nEpoch 20/24\n----------\ntrain Loss: 0.7589 Acc: 0.7812\nval Loss: 0.3005 Acc: 0.9051\n\nEpoch 21/24\n----------\ntrain Loss: 0.7463 Acc: 0.7834\nval Loss: 0.3007 Acc: 0.9054\n\nEpoch 22/24\n----------\ntrain Loss: 0.7478 Acc: 0.7831\nval Loss: 0.3010 Acc: 0.9054\n\nEpoch 23/24\n----------\ntrain Loss: 0.7450 Acc: 0.7828\nval Loss: 0.3022 Acc: 0.9054\n\nEpoch 24/24\n----------\ntrain Loss: 0.7521 Acc: 0.7845\nval Loss: 0.3021 Acc: 0.9052\n\nTraining complete in 98m 33s\nBest val Acc: 0.906557\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}