{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This code is for providing the data augmentation by using the YOLOv8 Architecture.\n",
    "\n",
    "Input : \n",
    "1. Directory Names of content images. [Healthy Leaf Directory of Different Plants]\n",
    "2. Directory Names of style images. [Hand Picked Infected Leaf Images of Different Plants]\n",
    "\n",
    "Output :\n",
    "1. Directory for all the style images where the augmented will be saved. [14 directories in case of segmented PlantVillage Dataset]\n",
    "2. This output will be used by the Augmentation Validation Classifier to include only relevent imgaes in the Actual Dataset.\n",
    "\n",
    "Functioning of this code : \n",
    "1. Initially we will find out the disparity in the dataset depending on the number of images present in the each class.\n",
    "2. Find mean number of images that should be present in each class and export this value for all the classes available. This value will be used to select top images from the augmented dataset.\n",
    "3. Then we will initiate the style transfer using the hand-picked styles from each class on the healty image datast for each crop and save the images in respective folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'ultralytics.nn.tasks.SegmentationModel'>\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch import optim\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms as T\n",
    "from scipy.spatial.distance import euclidean\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "\n",
    "device: str = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "model = YOLO('./models/yolov8x-seg.pt')\n",
    "yolo_model = model.model.model\n",
    "for parameters in yolo_model:\n",
    "    yolo_model.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv(\n",
       "    (conv): Conv2d(3, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (act): SiLU(inplace=True)\n",
       "  )\n",
       "  (1): Conv(\n",
       "    (conv): Conv2d(80, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (act): SiLU(inplace=True)\n",
       "  )\n",
       "  (2): C2f(\n",
       "    (cv1): Conv(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (cv2): Conv(\n",
       "      (conv): Conv2d(400, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (m): ModuleList(\n",
       "      (0-2): 3 x Bottleneck(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (3): Conv(\n",
       "    (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (act): SiLU(inplace=True)\n",
       "  )\n",
       "  (4): C2f(\n",
       "    (cv1): Conv(\n",
       "      (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (cv2): Conv(\n",
       "      (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (m): ModuleList(\n",
       "      (0-5): 6 x Bottleneck(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (5): Conv(\n",
       "    (conv): Conv2d(320, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (act): SiLU(inplace=True)\n",
       "  )\n",
       "  (6): C2f(\n",
       "    (cv1): Conv(\n",
       "      (conv): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (cv2): Conv(\n",
       "      (conv): Conv2d(2560, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (m): ModuleList(\n",
       "      (0-5): 6 x Bottleneck(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (7): Conv(\n",
       "    (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (act): SiLU(inplace=True)\n",
       "  )\n",
       "  (8): C2f(\n",
       "    (cv1): Conv(\n",
       "      (conv): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (cv2): Conv(\n",
       "      (conv): Conv2d(1600, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (m): ModuleList(\n",
       "      (0-2): 3 x Bottleneck(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (9): SPPF(\n",
       "    (cv1): Conv(\n",
       "      (conv): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (cv2): Conv(\n",
       "      (conv): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (10): Upsample(scale_factor=2.0, mode='nearest')\n",
       "  (11): Concat()\n",
       "  (12): C2f(\n",
       "    (cv1): Conv(\n",
       "      (conv): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (cv2): Conv(\n",
       "      (conv): Conv2d(1600, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (m): ModuleList(\n",
       "      (0-2): 3 x Bottleneck(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (13): Upsample(scale_factor=2.0, mode='nearest')\n",
       "  (14): Concat()\n",
       "  (15): C2f(\n",
       "    (cv1): Conv(\n",
       "      (conv): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (cv2): Conv(\n",
       "      (conv): Conv2d(800, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (m): ModuleList(\n",
       "      (0-2): 3 x Bottleneck(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (16): Conv(\n",
       "    (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (act): SiLU(inplace=True)\n",
       "  )\n",
       "  (17): Concat()\n",
       "  (18): C2f(\n",
       "    (cv1): Conv(\n",
       "      (conv): Conv2d(960, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (cv2): Conv(\n",
       "      (conv): Conv2d(1600, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (m): ModuleList(\n",
       "      (0-2): 3 x Bottleneck(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (19): Conv(\n",
       "    (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "    (act): SiLU(inplace=True)\n",
       "  )\n",
       "  (20): Concat()\n",
       "  (21): C2f(\n",
       "    (cv1): Conv(\n",
       "      (conv): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (cv2): Conv(\n",
       "      (conv): Conv2d(1600, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (m): ModuleList(\n",
       "      (0-2): 3 x Bottleneck(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (22): Segment(\n",
       "    (cv2): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Conv(\n",
       "          (conv): Conv2d(320, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv(\n",
       "          (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(80, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1-2): 2 x Sequential(\n",
       "        (0): Conv(\n",
       "          (conv): Conv2d(640, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv(\n",
       "          (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(80, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (cv3): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Conv(\n",
       "          (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv(\n",
       "          (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1-2): 2 x Sequential(\n",
       "        (0): Conv(\n",
       "          (conv): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv(\n",
       "          (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (dfl): DFL(\n",
       "      (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (proto): Proto(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (upsample): ConvTranspose2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv3): Conv(\n",
       "        (conv): Conv2d(320, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (cv4): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Conv(\n",
       "          (conv): Conv2d(320, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv(\n",
       "          (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(80, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1-2): 2 x Sequential(\n",
       "        (0): Conv(\n",
       "          (conv): Conv2d(640, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv(\n",
       "          (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(80, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "model_layers = {}\n",
    "for name, layer in model._modules.items():\n",
    "    for name_l, layer_l in layer._modules.items():\n",
    "        for name_ll, layer_ll in layer_l._modules.items():\n",
    "            model_layers[str(i)] = layer_ll\n",
    "            i += 1\n",
    "yolo_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentation code starts from here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_images_dir_list = [\n",
    "    '../data/PlantVillage/train/Apple___healthy',\n",
    "    '../data/PlantVillage/train/Corn_(maize)___healthy',\n",
    "    '../data/PlantVillage/train/Grape___healthy',\n",
    "    '../data/PlantVillage/train/Pepper,_bell___healthy',\n",
    "    '../data/PlantVillage/train/Strawberry___healthy',\n",
    "    '../data/PlantVillage/train/Tomato___healthy'\n",
    "]\n",
    "\n",
    "style_images_apple_dir_list = {\n",
    "    '../data/PlantVillage/train/Apple___Apple_scab': 100,\n",
    "    '../data/PlantVillage/train/Apple___Black_rot': 100,\n",
    "    '../data/PlantVillage/train/Apple___Cedar_apple_rust': 100,\n",
    "}\n",
    "\n",
    "style_images_corn_dir_list = {\n",
    "    '../data/PlantVillage/train/Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot': 100,\n",
    "    '../data/PlantVillage/train/Corn_(maize)___Common_rust_': 100,\n",
    "    'data/PlantVillage/train/Corn_(maize)___Northern_Leaf_Blight': 100, \n",
    "}\n",
    "\n",
    "style_images_grape_dir_list = {\n",
    "    '../data/PlantVillage/train/Grape___Black_rot':100,\n",
    "    '../data/PlantVillage/train/Grape___Esca_(Black_Measles)': 100,\n",
    "    '../data/PlantVillage/train/Grape___Leaf_blight_(Isariopsis_Leaf_Spot)':100,\n",
    "}\n",
    "\n",
    "style_images_pepper_dir_list = {\n",
    "    '../data/PlantVillage/train/Pepper,_bell___Bacterial_spot': 100,\n",
    "}\n",
    "\n",
    "style_images_strawberry_dir_list = {\n",
    "    '../data/PlantVillage/train/Strawberry___Leaf_scorch': 100,\n",
    "}\n",
    "\n",
    "style_images_tomato_dir_list = {\n",
    "    '../data/PlantVillage/train/Tomato___Bacterial_spot': 100,\n",
    "    '../data/PlantVillage/train/Tomato___Early_blight': 100, \n",
    "    '../data/PlantVillage/train/Tomato___Late_blight': 100, \n",
    "    '../data/PlantVillage/train/Tomato___Leaf_Mold': 100,\n",
    "    '../data/PlantVillage/train/Tomato___Septoria_leaf_spot': 100,\n",
    "    '../data/PlantVillage/train/Tomato___Spider_mites Two-spotted_spider_mite': 100,\n",
    "    '../data/PlantVillage/train/Tomato___Target_Spot': 100,\n",
    "    '../data/PlantVillage/train/Tomato___Tomato_mosaic_virus': 100,\n",
    "    '../data/PlantVillage/train/Tomato___Tomato_Yellow_Leaf_Curl_Virus': 100,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(img_path, max_size = 640):\n",
    "  image = Image.open(img_path).convert('RGB')\n",
    "  img_transforms = T.Compose([\n",
    "      T.ToTensor(),  # (224, 224, 3) -> (3, 224, 224)\n",
    "      T.Normalize(mean = [0.485, 0.456, 0.406],\n",
    "                  std = [0.229, 0.224, 0.225])\n",
    "  ])\n",
    "  image = img_transforms(image)\n",
    "  image = image.unsqueeze(0) # (3, 224, 224) -> (1, 3, 224, 224)\n",
    "  return image\n",
    "\n",
    "def deprocess(tensor):\n",
    "  image = tensor.to('cpu').clone()\n",
    "  image = image.numpy()\n",
    "  image = image.squeeze(0)\n",
    "  image = image.transpose(1, 2, 0)\n",
    "  # denormalizing the image\n",
    "  image = image * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "  image = image.clip(0, 1)\n",
    "  return image\n",
    "\n",
    "def get_features(image, model):\n",
    "  layers = {\n",
    "\n",
    "            '1' : 'conv1_1',\n",
    "            '2' : 'conv2_1',\n",
    "            '4' : 'conv3_1',\n",
    "            '7' : 'conv4_1',\n",
    "            '8' : 'conv4_2',\n",
    "            '10' : 'conv5_1'\n",
    "  }\n",
    "  x = image\n",
    "  Features = {}\n",
    "  i = 0\n",
    "  for name in model_layers.keys():\n",
    "    x = model_layers[name](x)\n",
    "    if name in layers:\n",
    "      Features[layers[name]] = x\n",
    "    i += 1\n",
    "    if (i > 10):\n",
    "      break\n",
    "  return Features\n",
    "\n",
    "def gram_matrix(tensor):\n",
    "  b, c, h, w = tensor.size()\n",
    "  tensor = tensor.view(c, h*w)\n",
    "  gram = torch.mm(tensor, tensor.t())\n",
    "  return gram\n",
    "\n",
    "def content_loss(target_conv4_2, content_conv4_2):\n",
    "  loss = torch.mean((target_conv4_2 - content_conv4_2)**2)\n",
    "  return loss\n",
    "\n",
    "style_weights_1 = {\n",
    "  'conv1_1' : 0.2,\n",
    "  'conv2_1' : 0.4,\n",
    "  'conv3_1' : 0.3,\n",
    "  'conv4_1' : 0.9,\n",
    "  'conv5_1' : 1.0\n",
    "}\n",
    "\n",
    "style_weights_2 = {\n",
    "  'conv1_1' : 1.0,\n",
    "  'conv2_1' : 0.4,\n",
    "  'conv3_1' : 0.3,\n",
    "  'conv4_1' : 0.2,\n",
    "  'conv5_1' : 0.1\n",
    "}\n",
    "\n",
    "style_weights_3 = {\n",
    "  'conv1_1' : 0.2,\n",
    "  'conv2_1' : 1.0,\n",
    "  'conv3_1' : 0.3,\n",
    "  'conv4_1' : 0.2,\n",
    "  'conv5_1' : 0.1\n",
    "}\n",
    "\n",
    "style_weights_4 = {\n",
    "  'conv1_1' : 0.2,\n",
    "  'conv2_1' : 0.4,\n",
    "  'conv3_1' : 1.0,\n",
    "  'conv4_1' : 0.2,\n",
    "  'conv5_1' : 0.1\n",
    "}\n",
    "\n",
    "style_weights_5 = {\n",
    "  'conv1_1' : 0.2,\n",
    "  'conv2_1' : 0.4,\n",
    "  'conv3_1' : 0.3,\n",
    "  'conv4_1' : 1.0,\n",
    "  'conv5_1' : 0.1\n",
    "}\n",
    "\n",
    "style_weights_arr = [style_weights_1, style_weights_2, style_weights_3, style_weights_4, style_weights_5]\n",
    "\n",
    "def style_loss(style_weights, target_features, style_grams):\n",
    "  loss = 0\n",
    "  for layer in style_weights:\n",
    "    target_f = target_features[layer]\n",
    "    target_gram = gram_matrix(target_f)\n",
    "    style_gram = style_grams[layer]\n",
    "    b, c, h, w = target_f.shape\n",
    "    layer_loss = style_weights[layer] * torch.mean((target_gram - style_gram)**2)\n",
    "    loss += layer_loss/(c*h*w)\n",
    "  return loss\n",
    "\n",
    "def total_loss(c_loss, s_loss, alpha, beta):\n",
    "  loss = alpha * c_loss + beta * s_loss\n",
    "  return loss\n",
    "\n",
    "def glcm_features(image):\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    glcm = graycomatrix(gray_image, [1], [0], 256, symmetric=True, normed=True)\n",
    "    contrast = graycoprops(glcm, 'contrast').flatten()\n",
    "    correlation = graycoprops(glcm, 'correlation').flatten()\n",
    "    energy = graycoprops(glcm, 'energy').flatten()\n",
    "    homogeneity = graycoprops(glcm, 'homogeneity').flatten()\n",
    "    return contrast, correlation, energy, homogeneity\n",
    "\n",
    "def calculate_similarity(feature1, feature2):\n",
    "    distance = 0\n",
    "    for f1, f2 in zip(feature1, feature2):\n",
    "        distance += (f1 - f2)**2\n",
    "    return distance**0.5\n",
    "\n",
    "def imread(path):\n",
    "    img = cv2.imread(path).astype(np.float)\n",
    "    if len(img.shape) == 2:\n",
    "        # grayscale\n",
    "        img = np.dstack((img,img,img))\n",
    "    elif img.shape[2] == 4:\n",
    "        # PNG with alpha channel\n",
    "        img = img[:,:,:3]\n",
    "    return img\n",
    "\n",
    "def imsave(path, img):\n",
    "    img = np.clip(img, 0, 255).astype(np.uint8)\n",
    "    Image.fromarray(img).save(path, quality=95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augment Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'ultralytics.nn.tasks.SegmentationModel'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "YOLO(\n",
       "  (model): SegmentationModel(\n",
       "    (model): Sequential(\n",
       "      (0): Conv(\n",
       "        (conv): Conv2d(3, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv(\n",
       "        (conv): Conv2d(80, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (2): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(400, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-2): 3 x Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): Conv(\n",
       "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (4): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-5): 6 x Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): Conv(\n",
       "        (conv): Conv2d(320, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (6): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(2560, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-5): 6 x Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): Conv(\n",
       "        (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (8): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(1600, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-2): 3 x Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): SPPF(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (10): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (11): Concat()\n",
       "      (12): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(1600, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-2): 3 x Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (13): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (14): Concat()\n",
       "      (15): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(800, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-2): 3 x Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (16): Conv(\n",
       "        (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (17): Concat()\n",
       "      (18): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(960, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(1600, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-2): 3 x Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (19): Conv(\n",
       "        (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (20): Concat()\n",
       "      (21): C2f(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(1600, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0-2): 3 x Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (22): Segment(\n",
       "        (cv2): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(320, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(80, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1-2): 2 x Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(640, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(80, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (cv3): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(320, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1-2): 2 x Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(320, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (dfl): DFL(\n",
       "          (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (proto): Proto(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (upsample): ConvTranspose2d(320, 320, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(320, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (cv4): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(320, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(80, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1-2): 2 x Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(640, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(80, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = YOLO('./models/custom-trained-yolov8-seg.pt')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nst_data_augment(content_img_path, style_img_path, final_image_name, final_image_path, style_weights):\n",
    "    content_p = preprocess(content_img_path)\n",
    "    style_p = preprocess(style_img_path)\n",
    "    content_p = content_p.to(device)\n",
    "    style_p = style_p.to(device)\n",
    "\n",
    "    #Getting the features from the image and calculation of Gram Matrix\n",
    "\n",
    "    content_f = get_features(content_p, yolo_model)\n",
    "    style_f = get_features(style_p, yolo_model)\n",
    "    style_grams = { layer : gram_matrix(style_f[layer]) for layer in style_f }\n",
    "    target = content_p.clone().requires_grad_(True).to(device)\n",
    "    target_f = get_features(target, yolo_model)\n",
    "\n",
    "    #Calculation of the losses and their optimization.\n",
    "\n",
    "    optimizer = optim.Adam([target], lr = 0.08)\n",
    "    alpha = 1\n",
    "    beta = 1e6\n",
    "    epochs = 1501\n",
    "    show_every = 500\n",
    "    results = []\n",
    "    for i in range(epochs):\n",
    "        target_f = get_features(target, yolo_model)\n",
    "\n",
    "        c_loss = content_loss(target_f['conv4_2'], content_f['conv4_2'])\n",
    "        s_loss = style_loss(style_weights, target_f, style_grams)\n",
    "\n",
    "        t_loss = total_loss(c_loss, s_loss, alpha, beta)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        t_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % show_every == 0:\n",
    "            print(\"Total loss at epoch {}: {}\".format(i, t_loss))\n",
    "            results.append(deprocess(target.detach()))\n",
    "\n",
    "    target_copy = deprocess(target.detach())\n",
    "    content_copy = deprocess(content_p)\n",
    "    plt.imsave(\"target.png\", target_copy)\n",
    "    plt.imsave(\"content.png\", content_copy)\n",
    "    imgcon = cv2.imread('content.png')\n",
    "    imgcon = cv2.cvtColor(imgcon, cv2.COLOR_BGR2RGB)\n",
    "    H, W, _ = imgcon.shape\n",
    "    results = model(imgcon)\n",
    "    i = 0\n",
    "    mask_present = 0\n",
    "    for result in results:\n",
    "        for j, mask in enumerate(result.masks.data):\n",
    "            mask = mask.cpu().numpy() * 255\n",
    "            mask  =cv2.resize(mask, (W, H))\n",
    "            cv2.imwrite('./mask.png', mask)\n",
    "            if i == 0:\n",
    "                mask_present = 1\n",
    "                break\n",
    "            i += 1\n",
    "    if (mask_present):\n",
    "        imgtar = cv2.imread(\"target.png\")\n",
    "        imgtar = cv2.cvtColor(imgtar, cv2.COLOR_BGR2RGB)\n",
    "        imgtar = imgtar.astype(np.uint8)\n",
    "        imgtar = cv2.resize(imgtar, (W, H))\n",
    "        mask = cv2.imread('./mask.png', cv2.IMREAD_GRAYSCALE)\n",
    "        _, binary_mask = cv2.threshold(mask, 1, 255, cv2.THRESH_BINARY)\n",
    "        masked_overlay = cv2.bitwise_or(imgtar, imgtar, mask=binary_mask)\n",
    "        masked_overlay = masked_overlay.astype(np.uint8)\n",
    "        inverted_mask = cv2.bitwise_not(binary_mask.astype(np.uint8))\n",
    "        roi = cv2.bitwise_and(imgcon, imgcon, mask=inverted_mask)\n",
    "        result_image = cv2.add(roi, masked_overlay)\n",
    "        plt.imsave(os.path.join(final_image_path, final_image_name), result_image)\n",
    "\n",
    "\n",
    "def nst_data_augment_without_segmentation(content_img_path, style_img_path, final_image_name, final_image_path, style_weights):\n",
    "    content_p = preprocess(content_img_path)\n",
    "    style_p = preprocess(style_img_path)\n",
    "    content_p = content_p.to(device)\n",
    "    style_p = style_p.to(device)\n",
    "\n",
    "    #Getting the features from the image and calculation of Gram Matrix\n",
    "\n",
    "    content_f = get_features(content_p, yolo_model)\n",
    "    style_f = get_features(style_p, yolo_model)\n",
    "    style_grams = { layer : gram_matrix(style_f[layer]) for layer in style_f }\n",
    "    target = content_p.clone().requires_grad_(True).to(device)\n",
    "    target_f = get_features(target, yolo_model)\n",
    "\n",
    "    #Calculation of the losses and their optimization.\n",
    "\n",
    "    optimizer = optim.Adam([target], lr = 0.08)\n",
    "    alpha = 1\n",
    "    beta = 1e6\n",
    "    epochs = 1501\n",
    "    show_every = 500\n",
    "    results = []\n",
    "    for i in range(epochs):\n",
    "        target_f = get_features(target, yolo_model)\n",
    "\n",
    "        c_loss = content_loss(target_f['conv4_2'], content_f['conv4_2'])\n",
    "        s_loss = style_loss(style_weights, target_f, style_grams)\n",
    "\n",
    "        t_loss = total_loss(c_loss, s_loss, alpha, beta)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        t_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % show_every == 0:\n",
    "            print(\"Total loss at epoch {}: {}\".format(i, t_loss))\n",
    "            results.append(deprocess(target.detach()))\n",
    "\n",
    "    target_copy = deprocess(target.detach())\n",
    "    plt.imsave(os.path.join(final_image_path, final_image_name), target_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_plant_dataset(content_data_dir, style_data_dir_list, final_output_directory, with_segmentation, style_weights, num_images):\n",
    "    for healthy_image_file in os.listdir(content_data_dir):\n",
    "        healthy_image_path = os.path.join(content_data_dir, healthy_image_file)\n",
    "        if os.path.isfile(healthy_image_path):\n",
    "            if (num_images > 0):\n",
    "                num_images -= 1\n",
    "            else:\n",
    "                break\n",
    "            healthy_image = cv2.imread(healthy_image_path)\n",
    "            if healthy_image is not None: \n",
    "                healthy_features = glcm_features(healthy_image)\n",
    "                for diseased_folder in style_data_dir_list:\n",
    "                    best_similarity = float('inf')\n",
    "                    best_diseased_leaf_image = None\n",
    "                    for diseased_image_file in os.listdir(os.path.join(diseased_folder)):\n",
    "                        diseased_image_path = os.path.join(diseased_folder, diseased_image_file)\n",
    "                        if os.path.isfile(diseased_image_path):\n",
    "                            diseased_image = cv2.imread(diseased_image_path)\n",
    "                            if diseased_image is not None:  # Check if image is loaded successfully\n",
    "                                diseased_features = glcm_features(diseased_image)\n",
    "                                similarity = calculate_similarity(healthy_features, diseased_features)\n",
    "                                if similarity < best_similarity:\n",
    "                                    best_similarity = similarity\n",
    "                                    best_diseased_leaf_image = diseased_image_path\n",
    "                    if best_diseased_leaf_image is not None:\n",
    "                        # print(f\"For healthy leaf image {healthy_image_file}, most similar diseased leaf image in folder {diseased_folder} is {best_diseased_leaf_image} with similarity score {best_similarity}\")\n",
    "                        index = diseased_folder.rfind(\"/\")\n",
    "                        diseased_folder_name = diseased_folder[index+1:]\n",
    "                        augmented_path = os.path.join(final_output_directory, diseased_folder_name)\n",
    "                        os.makedirs(augmented_path, exist_ok=True)\n",
    "                        index = healthy_image_file.rfind(\".\")\n",
    "                        augmented_image_name = healthy_image_file[:index] + \"_augmented.\" + healthy_image_file[index+1:]\n",
    "                        print(\"Transfering the style for : \" + str(healthy_image_path))\n",
    "                        if with_segmentation:\n",
    "                            nst_data_augment(healthy_image_path, best_diseased_leaf_image, augmented_image_name, augmented_path, style_weights)\n",
    "                        else:\n",
    "                            nst_data_augment_without_segmentation(healthy_image_path, best_diseased_leaf_image, augmented_image_name, augmented_path, style_weights)\n",
    "                    else:\n",
    "                        print(f\"No suitable diseased leaf image found for healthy leaf image {healthy_image_file} in folder {diseased_folder}\")\n",
    "            else:\n",
    "                print(f\"Error loading healthy leaf image: {healthy_image_path}\")\n",
    "        else:\n",
    "            print(f\"Invalid file: {healthy_image_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nst_data_augment('../data/plantvillage-dataset/segmented/apple_healthy/00a6039c-e425-4f7d-81b1-d6b0e668517e___RS_HL 7669_final_masked.jpg', '../data/shortlisted-style-images/apple_black_rot/4dadb9f1-27b1-4d3c-8111-d1602febd585___JR_FrgE.S 8632_final_masked.jpg', 'ouput.jpg', '../data/experiment-augmentation/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_required = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augment Apple Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transfering the style for : ../data/PlantVillage/train/Apple___healthy/4c7d424b-d418-4b72-84a9-2a639eabb5ec___RS_HL 5734.JPG\n",
      "Total loss at epoch 0: 908767936.0\n",
      "Total loss at epoch 500: 51322.01953125\n",
      "Total loss at epoch 1000: 13843.5244140625\n",
      "Total loss at epoch 1500: 1525989.625\n",
      "<ultralytics.models.yolo.segment.predict.SegmentationPredictor object at 0x352ce8a60>\n",
      "\n",
      "0: 640x640 1 Healthy_Leaf, 134.8ms\n",
      "Speed: 15.0ms preprocess, 134.8ms inference, 290.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Transfering the style for : ../data/PlantVillage/train/Apple___healthy/4c7d424b-d418-4b72-84a9-2a639eabb5ec___RS_HL 5734.JPG\n",
      "Total loss at epoch 0: 895906112.0\n",
      "Total loss at epoch 500: 107494.1484375\n",
      "Total loss at epoch 1000: 6359823.5\n",
      "Total loss at epoch 1500: 1744862.25\n",
      "\n",
      "0: 640x640 1 Healthy_Leaf, 154.2ms\n",
      "Speed: 14.1ms preprocess, 154.2ms inference, 128.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Transfering the style for : ../data/PlantVillage/train/Apple___healthy/4c7d424b-d418-4b72-84a9-2a639eabb5ec___RS_HL 5734.JPG\n",
      "Total loss at epoch 0: 3353571584.0\n",
      "Total loss at epoch 500: 216058.46875\n",
      "Total loss at epoch 1000: 70275.078125\n",
      "Total loss at epoch 1500: 38286.234375\n",
      "\n",
      "0: 640x640 1 Healthy_Leaf, 169.8ms\n",
      "Speed: 9.8ms preprocess, 169.8ms inference, 145.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Transfering the style for : ../data/PlantVillage/train/Apple___healthy/d5551b0d-594f-48c7-b689-c409145bf6cf___RS_HL 6325.JPG\n",
      "Total loss at epoch 0: 44206896.0\n",
      "Total loss at epoch 500: 60259.70703125\n",
      "Total loss at epoch 1000: 14713.8916015625\n",
      "Total loss at epoch 1500: 6750.03271484375\n",
      "\n",
      "0: 640x640 1 Healthy_Leaf, 183.2ms\n",
      "Speed: 8.1ms preprocess, 183.2ms inference, 158.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Transfering the style for : ../data/PlantVillage/train/Apple___healthy/d5551b0d-594f-48c7-b689-c409145bf6cf___RS_HL 6325.JPG\n",
      "Total loss at epoch 0: 45418924.0\n",
      "Total loss at epoch 500: 68657.8359375\n",
      "Total loss at epoch 1000: 20642.244140625\n",
      "Total loss at epoch 1500: 10641.626953125\n",
      "\n",
      "0: 640x640 1 Healthy_Leaf, 188.9ms\n",
      "Speed: 15.7ms preprocess, 188.9ms inference, 173.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Transfering the style for : ../data/PlantVillage/train/Apple___healthy/d5551b0d-594f-48c7-b689-c409145bf6cf___RS_HL 6325.JPG\n",
      "Total loss at epoch 0: 89204720.0\n",
      "Total loss at epoch 500: 194369.328125\n",
      "Total loss at epoch 1000: 50658.18359375\n",
      "Total loss at epoch 1500: 22396.224609375\n",
      "\n",
      "0: 640x640 1 Healthy_Leaf, 174.4ms\n",
      "Speed: 12.3ms preprocess, 174.4ms inference, 160.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Transfering the style for : ../data/PlantVillage/train/Apple___healthy/19b3dc29-de7d-46e8-af14-7451d779f424___RS_HL 7373.JPG\n",
      "Total loss at epoch 0: 83874952.0\n",
      "Total loss at epoch 500: 139593.203125\n",
      "Total loss at epoch 1000: 45033.5078125\n",
      "Total loss at epoch 1500: 24790.763671875\n",
      "\n",
      "0: 640x640 1 Healthy_Leaf, 164.1ms\n",
      "Speed: 8.7ms preprocess, 164.1ms inference, 288.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Transfering the style for : ../data/PlantVillage/train/Apple___healthy/19b3dc29-de7d-46e8-af14-7451d779f424___RS_HL 7373.JPG\n",
      "Total loss at epoch 0: 34635164.0\n",
      "Total loss at epoch 500: 68784.2265625\n",
      "Total loss at epoch 1000: 21001.052734375\n",
      "Total loss at epoch 1500: 11171.9951171875\n",
      "\n",
      "0: 640x640 1 Healthy_Leaf, 165.8ms\n",
      "Speed: 9.9ms preprocess, 165.8ms inference, 142.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Transfering the style for : ../data/PlantVillage/train/Apple___healthy/19b3dc29-de7d-46e8-af14-7451d779f424___RS_HL 7373.JPG\n",
      "Total loss at epoch 0: 161192736.0\n",
      "Total loss at epoch 500: 42952.21484375\n",
      "Total loss at epoch 1000: 14069.11328125\n",
      "Total loss at epoch 1500: 12232.2060546875\n",
      "\n",
      "0: 640x640 1 Healthy_Leaf, 167.1ms\n",
      "Speed: 17.6ms preprocess, 167.1ms inference, 150.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Transfering the style for : ../data/PlantVillage/train/Apple___healthy/9979c166-aa9e-4c63-af93-d9ad2b56bce2___RS_HL 5890.JPG\n",
      "Total loss at epoch 0: 237022272.0\n",
      "Total loss at epoch 500: 37770.79296875\n",
      "Total loss at epoch 1000: 18033.919921875\n",
      "Total loss at epoch 1500: 2358604.75\n",
      "\n",
      "0: 640x640 1 Healthy_Leaf, 178.7ms\n",
      "Speed: 14.0ms preprocess, 178.7ms inference, 254.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Transfering the style for : ../data/PlantVillage/train/Apple___healthy/9979c166-aa9e-4c63-af93-d9ad2b56bce2___RS_HL 5890.JPG\n",
      "Total loss at epoch 0: 19039886.0\n",
      "Total loss at epoch 500: 65694.640625\n",
      "Total loss at epoch 1000: 23710.095703125\n",
      "Total loss at epoch 1500: 13177.44921875\n",
      "\n",
      "0: 640x640 1 Healthy_Leaf, 265.3ms\n",
      "Speed: 28.3ms preprocess, 265.3ms inference, 180.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Transfering the style for : ../data/PlantVillage/train/Apple___healthy/9979c166-aa9e-4c63-af93-d9ad2b56bce2___RS_HL 5890.JPG\n",
      "Total loss at epoch 0: 151927936.0\n",
      "Total loss at epoch 500: 83687.40625\n",
      "Total loss at epoch 1000: 23410.13671875\n",
      "Total loss at epoch 1500: 10961.1923828125\n",
      "\n",
      "0: 640x640 1 Healthy_Leaf, 217.2ms\n",
      "Speed: 17.7ms preprocess, 217.2ms inference, 140.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Transfering the style for : ../data/PlantVillage/train/Apple___healthy/8c00ea10-bfc2-4d26-9dcf-afbf2dcd377a___RS_HL 7326.JPG\n",
      "Total loss at epoch 0: 100996856.0\n",
      "Total loss at epoch 500: 110030.953125\n",
      "Total loss at epoch 1000: 100361.3828125\n",
      "Total loss at epoch 1500: 4752586.5\n",
      "\n",
      "0: 640x640 1 Healthy_Leaf, 170.9ms\n",
      "Speed: 10.6ms preprocess, 170.9ms inference, 176.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Transfering the style for : ../data/PlantVillage/train/Apple___healthy/8c00ea10-bfc2-4d26-9dcf-afbf2dcd377a___RS_HL 7326.JPG\n",
      "Total loss at epoch 0: 296711904.0\n",
      "Total loss at epoch 500: 204380.71875\n",
      "Total loss at epoch 1000: 5572878.5\n",
      "Total loss at epoch 1500: 1687327.875\n",
      "\n",
      "0: 640x640 1 Healthy_Leaf, 254.3ms\n",
      "Speed: 22.8ms preprocess, 254.3ms inference, 153.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Transfering the style for : ../data/PlantVillage/train/Apple___healthy/8c00ea10-bfc2-4d26-9dcf-afbf2dcd377a___RS_HL 7326.JPG\n",
      "Total loss at epoch 0: 1135400576.0\n",
      "Total loss at epoch 500: 103298.9140625\n",
      "Total loss at epoch 1000: 29316.662109375\n",
      "Total loss at epoch 1500: 13704.939453125\n",
      "\n",
      "0: 640x640 1 Healthy_Leaf, 188.2ms\n",
      "Speed: 18.2ms preprocess, 188.2ms inference, 159.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Transfering the style for : ../data/PlantVillage/train/Apple___healthy/c69a5e33-20a9-4f74-922e-c3bc34b1c98e___RS_HL 7921.JPG\n",
      "Total loss at epoch 0: 394447424.0\n",
      "Total loss at epoch 500: 160012.609375\n",
      "Total loss at epoch 1000: 60232.21875\n",
      "Total loss at epoch 1500: 3236101.75\n",
      "\n",
      "0: 640x640 1 Healthy_Leaf, 158.9ms\n",
      "Speed: 9.7ms preprocess, 158.9ms inference, 154.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Transfering the style for : ../data/PlantVillage/train/Apple___healthy/c69a5e33-20a9-4f74-922e-c3bc34b1c98e___RS_HL 7921.JPG\n",
      "Total loss at epoch 0: 84083320.0\n",
      "Total loss at epoch 500: 101977.1796875\n",
      "Total loss at epoch 1000: 6617807.0\n",
      "Total loss at epoch 1500: 459203.15625\n",
      "\n",
      "0: 640x640 1 Healthy_Leaf, 194.6ms\n",
      "Speed: 10.2ms preprocess, 194.6ms inference, 182.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Transfering the style for : ../data/PlantVillage/train/Apple___healthy/c69a5e33-20a9-4f74-922e-c3bc34b1c98e___RS_HL 7921.JPG\n",
      "Total loss at epoch 0: 398878176.0\n",
      "Total loss at epoch 500: 47199.46484375\n",
      "Total loss at epoch 1000: 14345.3232421875\n",
      "Total loss at epoch 1500: 7948.27587890625\n",
      "\n",
      "0: 640x640 1 Healthy_Leaf, 199.9ms\n",
      "Speed: 5.8ms preprocess, 199.9ms inference, 185.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Transfering the style for : ../data/PlantVillage/train/Apple___healthy/a5da624b-8a38-4e64-ae7f-ace8b7c20548___RS_HL 5997.JPG\n",
      "Total loss at epoch 0: 276067520.0\n",
      "Total loss at epoch 500: 73223.375\n",
      "Total loss at epoch 1000: 17721.119140625\n",
      "Total loss at epoch 1500: 7378.333984375\n",
      "\n",
      "0: 640x640 1 Healthy_Leaf, 219.8ms\n",
      "Speed: 20.5ms preprocess, 219.8ms inference, 154.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Transfering the style for : ../data/PlantVillage/train/Apple___healthy/a5da624b-8a38-4e64-ae7f-ace8b7c20548___RS_HL 5997.JPG\n",
      "Total loss at epoch 0: 227097840.0\n",
      "Total loss at epoch 500: 191279.109375\n",
      "Total loss at epoch 1000: 69772.5078125\n",
      "Total loss at epoch 1500: 38046.8671875\n",
      "\n",
      "0: 640x640 1 Healthy_Leaf, 225.9ms\n",
      "Speed: 8.7ms preprocess, 225.9ms inference, 211.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Transfering the style for : ../data/PlantVillage/train/Apple___healthy/a5da624b-8a38-4e64-ae7f-ace8b7c20548___RS_HL 5997.JPG\n",
      "Total loss at epoch 0: 362574080.0\n",
      "Total loss at epoch 500: 152091.015625\n",
      "Total loss at epoch 1000: 38362.16015625\n",
      "Total loss at epoch 1500: 18067.1875\n",
      "\n",
      "0: 640x640 1 Healthy_Leaf, 239.3ms\n",
      "Speed: 11.3ms preprocess, 239.3ms inference, 225.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Transfering the style for : ../data/PlantVillage/train/Apple___healthy/8c850584-ade3-4067-bbf3-5c8602dba3c3___RS_HL 8175.JPG\n",
      "Total loss at epoch 0: 59690856.0\n",
      "Total loss at epoch 500: 26058.19140625\n",
      "Total loss at epoch 1000: 8928.50390625\n",
      "Total loss at epoch 1500: 845558.6875\n",
      "\n",
      "0: 640x640 1 Healthy_Leaf, 197.2ms\n",
      "Speed: 15.4ms preprocess, 197.2ms inference, 136.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Transfering the style for : ../data/PlantVillage/train/Apple___healthy/8c850584-ade3-4067-bbf3-5c8602dba3c3___RS_HL 8175.JPG\n",
      "Total loss at epoch 0: 51823872.0\n",
      "Total loss at epoch 500: 93297.1640625\n",
      "Total loss at epoch 1000: 29197.025390625\n",
      "Total loss at epoch 1500: 14817.6396484375\n",
      "\n",
      "0: 640x640 1 Healthy_Leaf, 248.4ms\n",
      "Speed: 9.8ms preprocess, 248.4ms inference, 243.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Transfering the style for : ../data/PlantVillage/train/Apple___healthy/8c850584-ade3-4067-bbf3-5c8602dba3c3___RS_HL 8175.JPG\n",
      "Total loss at epoch 0: 296145312.0\n",
      "Total loss at epoch 500: 99452.734375\n",
      "Total loss at epoch 1000: 32778.68359375\n",
      "Total loss at epoch 1500: 20748.642578125\n",
      "\n",
      "0: 640x640 1 Healthy_Leaf, 265.4ms\n",
      "Speed: 8.0ms preprocess, 265.4ms inference, 248.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Transfering the style for : ../data/PlantVillage/train/Apple___healthy/2514a94f-5f1b-4792-92e7-63b6a552225a___RS_HL 8186.JPG\n",
      "Total loss at epoch 0: 53765908.0\n",
      "Total loss at epoch 500: 19917.16015625\n",
      "Total loss at epoch 1000: 7323.52783203125\n",
      "Total loss at epoch 1500: 14835.78515625\n",
      "\n",
      "0: 640x640 1 Healthy_Leaf, 254.1ms\n",
      "Speed: 11.5ms preprocess, 254.1ms inference, 373.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Transfering the style for : ../data/PlantVillage/train/Apple___healthy/2514a94f-5f1b-4792-92e7-63b6a552225a___RS_HL 8186.JPG\n",
      "Total loss at epoch 0: 121874768.0\n",
      "Total loss at epoch 500: 23267.119140625\n",
      "Total loss at epoch 1000: 12297.6962890625\n",
      "Total loss at epoch 1500: 1883108.5\n",
      "\n",
      "0: 640x640 1 Healthy_Leaf, 271.4ms\n",
      "Speed: 18.7ms preprocess, 271.4ms inference, 236.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Transfering the style for : ../data/PlantVillage/train/Apple___healthy/2514a94f-5f1b-4792-92e7-63b6a552225a___RS_HL 8186.JPG\n",
      "Total loss at epoch 0: 37287788.0\n",
      "Total loss at epoch 500: 34914.06640625\n",
      "Total loss at epoch 1000: 11308.7880859375\n",
      "Total loss at epoch 1500: 516387.03125\n",
      "\n",
      "0: 640x640 1 Healthy_Leaf, 232.2ms\n",
      "Speed: 28.1ms preprocess, 232.2ms inference, 164.2ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Transfering the style for : ../data/PlantVillage/train/Apple___healthy/23a11b8b-6812-481e-9258-e07cc24fdad4___RS_HL 5898.JPG\n",
      "Total loss at epoch 0: 38157160.0\n",
      "Total loss at epoch 500: 17820.052734375\n",
      "Total loss at epoch 1000: 6227.41455078125\n",
      "Total loss at epoch 1500: 5312.78369140625\n",
      "\n",
      "0: 640x640 1 Healthy_Leaf, 197.0ms\n",
      "Speed: 18.7ms preprocess, 197.0ms inference, 189.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Transfering the style for : ../data/PlantVillage/train/Apple___healthy/23a11b8b-6812-481e-9258-e07cc24fdad4___RS_HL 5898.JPG\n",
      "Total loss at epoch 0: 44184172.0\n",
      "Total loss at epoch 500: 15815.8056640625\n",
      "Total loss at epoch 1000: 6354.85546875\n",
      "Total loss at epoch 1500: 1988878.875\n",
      "\n",
      "0: 640x640 1 Healthy_Leaf, 211.6ms\n",
      "Speed: 7.5ms preprocess, 211.6ms inference, 189.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Transfering the style for : ../data/PlantVillage/train/Apple___healthy/23a11b8b-6812-481e-9258-e07cc24fdad4___RS_HL 5898.JPG\n",
      "Total loss at epoch 0: 193329360.0\n",
      "Total loss at epoch 500: 19926.12890625\n",
      "Total loss at epoch 1000: 6019.369140625\n",
      "Total loss at epoch 1500: 3290.70068359375\n",
      "\n",
      "0: 640x640 1 Healthy_Leaf, 194.1ms\n",
      "Speed: 10.0ms preprocess, 194.1ms inference, 178.5ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Transfering the style for : ../data/PlantVillage/train/Apple___healthy/4c7d424b-d418-4b72-84a9-2a639eabb5ec___RS_HL 5734.JPG\n",
      "Total loss at epoch 0: 4542440960.0\n",
      "Total loss at epoch 500: 218925.484375\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(style_weights_arr)):\n\u001b[0;32m----> 2\u001b[0m     \u001b[43maugment_plant_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent_images_dir_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstyle_images_apple_dir_list\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../data/plantvillage-augmented/weights_\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstyle_weights_arr\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_required\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[47], line 35\u001b[0m, in \u001b[0;36maugment_plant_dataset\u001b[0;34m(content_data_dir, style_data_dir_list, final_output_directory, with_segmentation, style_weights, num_images)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTransfering the style for : \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(healthy_image_path))\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m with_segmentation:\n\u001b[0;32m---> 35\u001b[0m     \u001b[43mnst_data_augment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhealthy_image_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbest_diseased_leaf_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugmented_image_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugmented_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstyle_weights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     37\u001b[0m     nst_data_augment_without_segmentation(healthy_image_path, best_diseased_leaf_image, augmented_image_name, augmented_path, style_weights)\n",
      "Cell \u001b[0;32mIn[46], line 24\u001b[0m, in \u001b[0;36mnst_data_augment\u001b[0;34m(content_img_path, style_img_path, final_image_name, final_image_path, style_weights)\u001b[0m\n\u001b[1;32m     22\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m---> 24\u001b[0m     target_f \u001b[38;5;241m=\u001b[39m \u001b[43mget_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myolo_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     c_loss \u001b[38;5;241m=\u001b[39m content_loss(target_f[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconv4_2\u001b[39m\u001b[38;5;124m'\u001b[39m], content_f[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconv4_2\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     27\u001b[0m     s_loss \u001b[38;5;241m=\u001b[39m style_loss(style_weights, target_f, style_grams)\n",
      "Cell \u001b[0;32mIn[44], line 36\u001b[0m, in \u001b[0;36mget_features\u001b[0;34m(image, model)\u001b[0m\n\u001b[1;32m     34\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m model_layers\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m---> 36\u001b[0m   x \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_layers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m layers:\n\u001b[1;32m     38\u001b[0m     Features[layers[name]] \u001b[38;5;241m=\u001b[39m x\n",
      "File \u001b[0;32m~/miniconda3/envs/plant-torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/plant-torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/plant-torch/lib/python3.9/site-packages/torch/nn/modules/upsampling.py:156\u001b[0m, in \u001b[0;36mUpsample.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpolate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_factor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malign_corners\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mrecompute_scale_factor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecompute_scale_factor\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/plant-torch/lib/python3.9/site-packages/torch/nn/functional.py:3983\u001b[0m, in \u001b[0;36minterpolate\u001b[0;34m(input, size, scale_factor, mode, align_corners, recompute_scale_factor, antialias)\u001b[0m\n\u001b[1;32m   3981\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39mupsample_nearest1d(\u001b[38;5;28minput\u001b[39m, output_size, scale_factors)\n\u001b[1;32m   3982\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m4\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnearest\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 3983\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupsample_nearest2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_factors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3984\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m5\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnearest\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   3985\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39mupsample_nearest3d(\u001b[38;5;28minput\u001b[39m, output_size, scale_factors)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(len(style_weights_arr)):\n",
    "    augment_plant_dataset(content_images_dir_list[0], list(style_images_apple_dir_list.keys()), '../data/plantvillage-augmented/weights_'+str(i)+\"/\", True, style_weights_arr[i], num_required)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augment Corn Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augment_plant_dataset(content_images_dir_list[1], list(style_images_corn_dir_list.keys()), '../data/plantvillage-augmented/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augment Tomato Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augment_plant_dataset(content_images_dir_list[2], list(style_images_tomato_dir_list.keys()), '../data/plantvillage-augmented/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'ultralytics.nn.tasks.SegmentationModel'>\n",
      "<ultralytics.models.yolo.segment.predict.SegmentationPredictor object at 0x171cac8e0>\n",
      "\n",
      "0: 640x640 1 Non_Healthy_Leaf, 917.5ms\n",
      "Speed: 1.6ms preprocess, 917.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "model = YOLO('./models/custom-trained-yolov8-seg.pt')\n",
    "img = cv2.imread('../data/PlantVillage/train/Tomato___healthy/000bf685-b305-408b-91f4-37030f8e62db___GH_HL Leaf 308.1.JPG')\n",
    "\n",
    "# Set confidence threshold\n",
    "conf = 0.5\n",
    "\n",
    "# Predict using the model\n",
    "results = model.predict(img, conf=conf)\n",
    "\n",
    "# Create a black image of the same dimensions as the input image\n",
    "binary_mask = np.zeros_like(img)\n",
    "binary_mask.fill(0) # Making the image black\n",
    "\n",
    "for result in results:\n",
    "    for mask, box in zip(result.masks.xy, result.boxes):\n",
    "        points = np.int32([mask])\n",
    "        # Use white color for the segmented region, making it visible against the black background\n",
    "        cv2.fillPoly(binary_mask, points, (255, 255, 255))\n",
    "\n",
    "# Display the binary mask\n",
    "# cv2.imshow(binary_mask)\n",
    "# cv2.waitKey(0)\n",
    "\n",
    "# Save the binary mask image\n",
    "cv2.imwrite(\"./mask.jpg\", binary_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "as such change kahich nahi kela, just used the backbone of YOLOv8 for getting the features out from the content and style image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
