{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "def imread(path):\n",
    "    img = cv2.imread(path).astype(np.float)\n",
    "    if len(img.shape) == 2:\n",
    "        # grayscale\n",
    "        img = np.dstack((img,img,img))\n",
    "    elif img.shape[2] == 4:\n",
    "        # PNG with alpha channel\n",
    "        img = img[:,:,:3]\n",
    "    return img\n",
    "\n",
    "def imsave(path, img):\n",
    "    img = np.clip(img, 0, 255).astype(np.uint8)\n",
    "    Image.fromarray(img).save(path, quality=95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'ultralytics.nn.tasks.SegmentationModel'>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "\n",
    "device: str = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "model = YOLO('./nst/models/yolov8x-seg.pt')  # load a pretrained YOLOv8n segmentation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ultralytics.models.yolo.segment.predict.SegmentationPredictor object at 0x17e95ad60>\n",
      "\n",
      "0: 640x480 1 vase, 797.2ms\n",
      "Speed: 9.1ms preprocess, 797.2ms inference, 16.0ms postprocess per image at shape (1, 3, 640, 480)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "imgcon = cv2.imread('content.png')\n",
    "H, W, _ = imgcon.shape\n",
    "results = model(imgcon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in results:\n",
    "    for j, mask in enumerate(result.masks.data):\n",
    "        mask = mask.cpu().numpy() * 255\n",
    "        mask  =cv2.resize(mask, (W, H))\n",
    "        cv2.imwrite('./mask.png', mask)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgtar = cv2.imread(\"target.png\")\n",
    "imgtar = cv2.cvtColor(imgtar, cv2.COLOR_BGR2RGB)\n",
    "imgtar = imgtar.astype(np.uint8)\n",
    "imgtar = cv2.resize(imgtar, (W, H))\n",
    "mask = cv2.imread('./mask.png', cv2.IMREAD_GRAYSCALE)\n",
    "_, binary_mask = cv2.threshold(mask, 1, 255, cv2.THRESH_BINARY)\n",
    "masked_overlay = cv2.bitwise_or(imgtar, imgtar, mask=binary_mask)\n",
    "masked_overlay = masked_overlay.astype(np.uint8)\n",
    "inverted_mask = cv2.bitwise_not(binary_mask.astype(np.uint8))\n",
    "roi = cv2.bitwise_and(imgcon, imgcon, mask=inverted_mask)\n",
    "result_image = cv2.add(roi, masked_overlay)\n",
    "imsave('./final_output.png', result_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plant-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
